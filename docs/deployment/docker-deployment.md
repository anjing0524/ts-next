# Docker ä¸ Kubernetes éƒ¨ç½²æŒ‡å—

æœ¬æŒ‡å—è¯¦ç»†ä»‹ç»äº†å¦‚ä½•å°† TS Next Template é¡¹ç›®éƒ¨ç½²åˆ° Docker å’Œ Kubernetes ç¯å¢ƒï¼ŒåŒ…å«å®Œæ•´çš„å¾®æœåŠ¡æ¶æ„éƒ¨ç½²æ–¹æ¡ˆã€‚

## ğŸ³ Docker éƒ¨ç½²

### 1. ç¯å¢ƒå‡†å¤‡

#### å¿…éœ€è½¯ä»¶
- [Docker](https://docs.docker.com/get-docker/) (v24.0+)
- [Docker Compose](https://docs.docker.com/compose/) (v2.0+)
- [kubectl](https://kubernetes.io/docs/tasks/tools/) (ç”¨äº Kubernetes)

### 2. æœåŠ¡é•œåƒæ„å»º

#### 2.1 æ„å»ºæ‰€æœ‰æœåŠ¡é•œåƒ

```bash
# æ„å»ºæ‰€æœ‰æœåŠ¡é•œåƒ
pnpm build:docker

# æˆ–è€…åˆ†åˆ«æ„å»ºæ¯ä¸ªæœåŠ¡
docker build -f apps/oauth-service/Dockerfile -t ts-next/oauth-service:latest .
docker build -f apps/admin-portal/Dockerfile -t ts-next/admin-portal:latest .
docker build -f apps/kline-service/Dockerfile -t ts-next/kline-service:latest .
docker build -f apps/pingora-proxy/Dockerfile -t ts-next/pingora-proxy:latest .
```

#### 2.2 åŸºç¡€é•œåƒæ„å»º

ä½¿ç”¨å¤šé˜¶æ®µæ„å»ºä¼˜åŒ–é•œåƒå¤§å°ï¼š

```dockerfile
# apps/oauth-service/Dockerfile
FROM node:20-alpine AS base
WORKDIR /app

# å®‰è£… pnpm
RUN npm install -g pnpm@10.6.2

# ä¾èµ–é˜¶æ®µ
FROM base AS deps
COPY package.json pnpm-lock.yaml* ./
RUN pnpm install --frozen-lockfile --prefer-offline

# æ„å»ºé˜¶æ®µ
FROM base AS builder
COPY --from=deps /app/node_modules ./node_modules
COPY . .
RUN pnpm --filter=oauth-service build

# ç”Ÿäº§é˜¶æ®µ
FROM node:20-alpine AS runner
WORKDIR /app

ENV NODE_ENV=production
ENV PORT=3001

COPY --from=builder /app/apps/oauth-service/.next/standalone ./
COPY --from=builder /app/apps/oauth-service/.next/static ./.next/static
COPY --from=builder /app/apps/oauth-service/public ./public

EXPOSE 3001
CMD ["node", "server.js"]
```

### 3. Docker Compose éƒ¨ç½²

#### 3.1 åˆ›å»º docker-compose.yml

```yaml
version: '3.8'

services:
  # OAuth æœåŠ¡
  oauth-service:
    build:
      context: .
      dockerfile: apps/oauth-service/Dockerfile
    ports:
      - "3001:3001"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/oauth_db
      - REDIS_URL=redis://redis:6379
      - JWT_PRIVATE_KEY_PATH=/app/keys/private.pem
      - JWT_PUBLIC_KEY_PATH=/app/keys/public.pem
    volumes:
      - ./keys:/app/keys:ro
      - oauth_logs:/app/logs
    depends_on:
      - postgres
      - redis
    networks:
      - app-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ç®¡ç†åå°
  admin-portal:
    build:
      context: .
      dockerfile: apps/admin-portal/Dockerfile
    ports:
      - "3002:3002"
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_OAUTH_SERVICE_URL=http://oauth-service:3001
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/admin_db
    depends_on:
      - postgres
      - oauth-service
    networks:
      - app-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3002/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # é‡‘èæ•°æ®æœåŠ¡
  kline-service:
    build:
      context: .
      dockerfile: apps/kline-service/Dockerfile
    ports:
      - "3003:3003"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/kline_db
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - app-network
    restart: unless-stopped

  # Pingora ä»£ç†
  pingora-proxy:
    build:
      context: .
      dockerfile: apps/pingora-proxy/Dockerfile
    ports:
      - "6188:6188"
    environment:
      - NODE_ENV=production
    depends_on:
      - oauth-service
      - admin-portal
      - kline-service
    networks:
      - app-network
    restart: unless-stopped

  # PostgreSQL æ•°æ®åº“
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=main_db
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    ports:
      - "5432:5432"
    networks:
      - app-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis ç¼“å­˜
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - app-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  postgres_data:
  redis_data:
  oauth_logs:

networks:
  app-network:
    driver: bridge
```

#### 3.2 å¯åŠ¨æœåŠ¡

```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f oauth-service
docker-compose logs -f admin-portal

# åœæ­¢æœåŠ¡
docker-compose down

# æ¸…ç†æ•°æ®å·
docker-compose down -v
```

### 4. ç¯å¢ƒå˜é‡é…ç½®

#### 4.1 ç”Ÿäº§ç¯å¢ƒå˜é‡ (.env.production)

```bash
# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql://user:password@postgres:5432/main_db
REDIS_URL=redis://redis:6379

# OAuth é…ç½®
JWT_PRIVATE_KEY_PATH=/app/keys/private.pem
JWT_PUBLIC_KEY_PATH=/app/keys/public.pem
JWT_KEY_ID=production-key-2024
JWT_ISSUER=https://your-domain.com
JWT_AUDIENCE=your-app-name

# æœåŠ¡é…ç½®
NEXT_PUBLIC_OAUTH_SERVICE_URL=http://oauth-service:3001
NEXTAUTH_URL=http://admin-portal:3002
NEXTAUTH_SECRET=your-production-secret

# æ—¥å¿—é…ç½®
LOG_LEVEL=info
LOG_FILE_PATH=/app/logs/app.log

# å®‰å…¨é…ç½®
NODE_ENV=production
PORT=3001
```

## â˜¸ï¸ Kubernetes éƒ¨ç½²

### 1. æ¶æ„æ¦‚è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Ingress                              â”‚
â”‚                   (pingora-proxy)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚             â”‚             â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”
â”‚oauth- â”‚    â”‚admin- â”‚    â”‚kline- â”‚
â”‚serviceâ”‚    â”‚portal â”‚    â”‚serviceâ”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”˜    â””â”€â”€â”€â”¬â”€â”€â”€â”˜    â””â”€â”€â”€â”¬â”€â”€â”€â”˜
    â”‚            â”‚            â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”        â”‚
â”‚postgresâ”‚    â”‚redis  â”‚        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
                              â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                       â”‚WASMè®¡ç®—æ¨¡å—  â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. å‘½åç©ºé—´é…ç½®

```yaml
# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: ts-next-template
  labels:
    name: ts-next-template
    environment: production
```

### 3. æœåŠ¡é…ç½®

#### 3.1 OAuth æœåŠ¡éƒ¨ç½²

```yaml
# k8s/oauth-service/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: oauth-service
  namespace: ts-next-template
spec:
  replicas: 3
  selector:
    matchLabels:
      app: oauth-service
  template:
    metadata:
      labels:
        app: oauth-service
    spec:
      containers:
      - name: oauth-service
        image: ts-next/oauth-service:latest
        ports:
        - containerPort: 3001
        env:
        - name: NODE_ENV
          value: "production"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: database-url
        - name: REDIS_URL
          value: "redis://redis-service:6379"
        - name: JWT_PRIVATE_KEY
          valueFrom:
            secretKeyRef:
              name: jwt-secret
              key: private-key
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 3001
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 3001
          initialDelaySeconds: 5
          periodSeconds: 5
        volumeMounts:
        - name: keys
          mountPath: /app/keys
          readOnly: true
      volumes:
      - name: keys
        secret:
          secretName: jwt-keys
```

#### 3.2 Admin Portal éƒ¨ç½²

```yaml
# k8s/admin-portal/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: admin-portal
  namespace: ts-next-template
spec:
  replicas: 2
  selector:
    matchLabels:
      app: admin-portal
  template:
    metadata:
      labels:
        app: admin-portal
    spec:
      containers:
      - name: admin-portal
        image: ts-next/admin-portal:latest
        ports:
        - containerPort: 3002
        env:
        - name: NODE_ENV
          value: "production"
        - name: NEXT_PUBLIC_OAUTH_SERVICE_URL
          value: "http://oauth-service:3001"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: database-url
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /api/health
            port: 3002
          initialDelaySeconds: 30
          periodSeconds: 10
```

#### 3.3 æœåŠ¡å‘ç°é…ç½®

```yaml
# k8s/services.yaml
apiVersion: v1
kind: Service
metadata:
  name: oauth-service
  namespace: ts-next-template
spec:
  selector:
    app: oauth-service
  ports:
  - port: 3001
    targetPort: 3001
  type: ClusterIP

---
apiVersion: v1
kind: Service
metadata:
  name: admin-portal
  namespace: ts-next-template
spec:
  selector:
    app: admin-portal
  ports:
  - port: 3002
    targetPort: 3002
  type: ClusterIP

---
apiVersion: v1
kind: Service
metadata:
  name: kline-service
  namespace: ts-next-template
spec:
  selector:
    app: kline-service
  ports:
  - port: 3003
    targetPort: 3003
  type: ClusterIP
```

### 4. é…ç½®ç®¡ç†

#### 4.1 ConfigMap é…ç½®

```yaml
# k8s/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: ts-next-template
data:
  NODE_ENV: "production"
  LOG_LEVEL: "info"
  JWT_ISSUER: "https://your-domain.com"
  JWT_AUDIENCE: "ts-next-template"
```

#### 4.2 Secret é…ç½®

```yaml
# k8s/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: postgres-secret
  namespace: ts-next-template
type: Opaque
data:
  username: cG9zdGdyZXM=  # base64 encoded 'postgres'
  password: cGFzc3dvcmQ=  # base64 encoded 'password'
  database-url: cG9zdGdyZXNxbDovL3Bvc3RncmVzOnBhc3N3b3JkQHBvc3RncmVzLXNlcnZpY2U6NTQzMi9tYWluX2Ri

---
apiVersion: v1
kind: Secret
metadata:
  name: jwt-secret
  namespace: ts-next-template
type: Opaque
data:
  private-key: LS0tLS1CRUdJTiBQUklWQVRFIEtFWS0tLS0t...  # base64 encoded private key
  public-key: LS0tLS1CRUdJTiBQVUJMSUMgS0VZLS0tLS0...   # base64 encoded public key
```

### 5. Ingress é…ç½®

```yaml
# k8s/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ts-next-ingress
  namespace: ts-next-template
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  tls:
  - hosts:
    - your-domain.com
    secretName: ts-next-tls
  rules:
  - host: your-domain.com
    http:
      paths:
      - path: /oauth
        pathType: Prefix
        backend:
          service:
            name: oauth-service
            port:
              number: 3001
      - path: /admin
        pathType: Prefix
        backend:
          service:
            name: admin-portal
            port:
              number: 3002
      - path: /api/kline
        pathType: Prefix
        backend:
          service:
            name: kline-service
            port:
              number: 3003
```

### 6. éƒ¨ç½²è„šæœ¬

#### 6.1 ä¸€é”®éƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# scripts/deploy-k8s.sh

set -e

NAMESPACE=${NAMESPACE:-ts-next-template}
IMAGE_TAG=${IMAGE_TAG:-latest}

echo "ğŸš€ Deploying TS Next Template to Kubernetes..."

# åˆ›å»ºå‘½åç©ºé—´
kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -

# åº”ç”¨é…ç½®
kubectl apply -f k8s/namespace.yaml
kubectl apply -f k8s/configmap.yaml
kubectl apply -f k8s/secrets.yaml
kubectl apply -f k8s/services.yaml
kubectl apply -f k8s/deployments/
kubectl apply -f k8s/ingress.yaml

# ç­‰å¾…éƒ¨ç½²å®Œæˆ
kubectl rollout status deployment/oauth-service -n $NAMESPACE
kubectl rollout status deployment/admin-portal -n $NAMESPACE
kubectl rollout status deployment/kline-service -n $NAMESPACE

echo "âœ… Deployment completed successfully!"
```

#### 6.2 éªŒè¯éƒ¨ç½²

```bash
#!/bin/bash
# scripts/verify-deployment.sh

NAMESPACE=${NAMESPACE:-ts-next-template}

echo "ğŸ” Checking deployment status..."

# æ£€æŸ¥ Pod çŠ¶æ€
kubectl get pods -n $NAMESPACE

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
kubectl get services -n $NAMESPACE

# æ£€æŸ¥ Ingress çŠ¶æ€
kubectl get ingress -n $NAMESPACE

# æµ‹è¯•æœåŠ¡è¿æ¥
kubectl run test-pod --image=curlimages/curl --rm -it --restart=Never -- \
  curl http://oauth-service:3001/health

echo "âœ… All services are running correctly!"
```

### 7. ç›‘æ§ä¸æ—¥å¿—

#### 7.1 ç›‘æ§é…ç½®

```yaml
# k8s/monitoring.yaml
apiVersion: v1
kind: ServiceMonitor
metadata:
  name: ts-next-monitor
  namespace: ts-next-template
spec:
  selector:
    matchLabels:
      app: ts-next-template
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
```

#### 7.2 æ—¥å¿—èšåˆ

```yaml
# k8s/logging.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-config
  namespace: ts-next-template
data:
  fluent-bit.conf: |
    [SERVICE]
        Flush         1
        Log_Level     info
        Daemon        off

    [INPUT]
        Name              tail
        Path              /var/log/containers/*.log
        Parser            docker
        Tag               kube.*
        Refresh_Interval  5

    [OUTPUT]
        Name  es
        Match *
        Host  elasticsearch.logging.svc.cluster.local
        Port  9200
        Logstash_Format On
        Retry_Limit False
```

## ğŸš€ ç”Ÿäº§éƒ¨ç½²æœ€ä½³å®è·µ

### 1. å®‰å…¨åŠ å›º

#### 1.1 ç½‘ç»œå®‰å…¨
```yaml
# ç½‘ç»œç­–ç•¥
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: ts-next-network-policy
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
```

#### 1.2 RBAC é…ç½®
```yaml
# RBAC é…ç½®
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: ts-next-role
rules:
- apiGroups: [""]
  resources: ["pods", "services", "configmaps"]
  verbs: ["get", "list", "watch"]
```

### 2. æ€§èƒ½ä¼˜åŒ–

#### 2.1 èµ„æºé™åˆ¶
```yaml
resources:
  requests:
    memory: "256Mi"
    cpu: "250m"
  limits:
    memory: "512Mi"
    cpu: "500m"
```

#### 2.2 HPA é…ç½®
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: oauth-service-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: oauth-service
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

### 3. å¤‡ä»½ç­–ç•¥

#### 3.1 æ•°æ®åº“å¤‡ä»½
```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: postgres-backup
spec:
  schedule: "0 2 * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: postgres:15-alpine
            command:
            - pg_dump
            - -h
            - postgres-service
            - -U
            - postgres
            - main_db
            - "> /backup/backup-$(date +%Y%m%d-%H%M%S).sql"
```

## ğŸ“‹ éƒ¨ç½²æ£€æŸ¥æ¸…å•

### éƒ¨ç½²å‰æ£€æŸ¥
- [ ] æ‰€æœ‰é•œåƒå·²æ„å»ºå¹¶æ¨é€åˆ°é•œåƒä»“åº“
- [ ] æ‰€æœ‰é…ç½®æ–‡ä»¶å·²æ›´æ–°ä¸ºç”Ÿäº§ç¯å¢ƒé…ç½®
- [ ] æ‰€æœ‰å¯†é’¥å·²æ­£ç¡®é…ç½®
- [ ] åŸŸåå’Œ SSL è¯ä¹¦å·²é…ç½®

### éƒ¨ç½²åéªŒè¯
- [ ] æ‰€æœ‰ Pod æ­£å¸¸è¿è¡Œ
- [ ] æ‰€æœ‰æœåŠ¡å¯æ­£å¸¸è®¿é—®
- [ ] æ•°æ®åº“è¿æ¥æ­£å¸¸
- [ ] Redis ç¼“å­˜æ­£å¸¸
- [ ] æ—¥å¿—æ”¶é›†æ­£å¸¸
- [ ] ç›‘æ§å‘Šè­¦æ­£å¸¸

### æ•…éšœæ’é™¤
```bash
# æŸ¥çœ‹ Pod çŠ¶æ€
kubectl get pods -n ts-next-template

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
kubectl get svc -n ts-next-template

# æŸ¥çœ‹æ—¥å¿—
kubectl logs -f deployment/oauth-service -n ts-next-template

# è¿›å…¥ Pod è°ƒè¯•
kubectl exec -it deployment/oauth-service -n ts-next-template -- /bin/sh

# ç«¯å£è½¬å‘è°ƒè¯•
kubectl port-forward svc/oauth-service 3001:3001 -n ts-next-template
```

## ğŸ”§ ç»´æŠ¤ä¸æ›´æ–°

### æ»šåŠ¨æ›´æ–°
```bash
# æ›´æ–°é•œåƒ
kubectl set image deployment/oauth-service oauth-service=ts-next/oauth-service:v2.0.0 -n ts-next-template

# å›æ»šæ›´æ–°
kubectl rollout undo deployment/oauth-service -n ts-next-template

# æŸ¥çœ‹æ›´æ–°çŠ¶æ€
kubectl rollout status deployment/oauth-service -n ts-next-template
```

### æ¸…ç†èµ„æº
```bash
# åˆ é™¤æ‰€æœ‰èµ„æº
kubectl delete namespace ts-next-template

# æ¸…ç†æŒä¹…å·
kubectl delete pvc --all -n ts-next-template
```